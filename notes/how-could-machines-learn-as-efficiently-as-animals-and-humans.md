## Notes on the public lecture: How Could Machines Learn as Efficiently as Animals and Humans
Watch the lecture [here](https://youtu.be/0BUr4_ZkA1w)

## Detailed Note
The lecture contained two major parts (past/present works and then future works). In the first part, the presenter gave an overview of Machine/Deep Learning from Computer Vision perspective (i.e. Convolutional Neural Networks). In second part, the presenter described what he believes is the next frontier for Machine/Deep Learning also from Computer Vision perspective. He calls this frontier Predictive Learning - a type of unsupervised learning where the machine (or intelligent agent) is taught common sense (e.g. about gravity) by watching video. The idea is for the machine to watch the video to a certain point (then maybe the video is paused) and then the its given a task of generating what the future frames (images) of the video. The presenter draws inspiration from human understanding of intuitive physics. *For example, if someone throws a ball up while our eyes are closed, and then we open our eyes with the ball descending mid-way in the air, we can predict the near future that the ball will fall back to the ground because of gravity*. This kind of common sense is what the presenter is trying to teach machines. For the machine to generate these kind of future frames predictions, it needs to be able to generate images. This is where generative modelling techniques comes into play here. The presenter sees Generative Adversarial Network (GAN) ([Wikipedia](https://en.wikipedia.org/wiki/Generative_adversarial_network), [original paper](https://arxiv.org/abs/1406.2661)) as the main approach here. Here is a [link](https://arxiv.org/abs/1609.03126) to a work on GANs for Predictive Learning.

### Food for thought
It is known that GANs are quite difficult to train and unstable at the moment and that more research is being devoted to stabilizing GANs. Given the above states of GANs, maybe other generative modelling techniques can be applied to Predictive Learning (learning common sense). For example, Variational Auto-Encoders (VAE) comes to mind. Has any research been carried out to apply VAEs in Predictive Learning?
