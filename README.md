# reading-list

Links to articles, blog posts, research papers, videos that I have read(watched) or will read(watch) in the future.

## Unread
`[Metalearning`] - article
https://www.cifar.ca/assets/machines-learn-new-ways-of-learning/
Quick Note: 

`[Synthetic Gradients`] - blogpost
http://iamtrask.github.io/2017/03/21/synthetic-gradients/
Quick Note: rather than actually compute gradient via backprop, each NN layer approximates their gradient by learning.

`[Information bottleneck`] - article
https://www.quantamagazine.org/new-theory-cracks-open-the-black-box-of-deep-learning-20170921/
Quick Note: link to an article written about a talk about potential explanation of why neural net works was given.

`[about-sgd`] - blogpost
https://medium.com/intuitionmachine/the-peculiar-behavior-of-deep-learning-loss-surfaces-330cb741ec17
Quick Note: 

`[Meta Learning`] - research paper
https://arxiv.org/abs/1709.07417
Quick Note: neural optimizer. authors learnt new optimizers from cifar-10 dataset and claim that they generalise to other tasks.

[CMU Fall 2017 NLP Course] - video
https://www.youtube.com/watch?v=Sss2EA4hhBQ&list=PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT
Quick Note:

[Learning Through Interation: Generalisation in Robot RL] - video
https://www.youtube.com/watch?v=Ko8IBbYjdq8
Quick Note:

## Read
